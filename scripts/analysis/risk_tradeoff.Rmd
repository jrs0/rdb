---
title: "Modelling Bleeding and Ischaemia Risk in Patients Prescribed Dual Antiplatelet Therapy"
subtitle: "Classification models based on diagnosis/procedures codes from HES data"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)

## This option helps keep printed R vectors within
## the margins in the PDF
options("width"=100)

if (!exists("scripts_have_run")) {
    source("run_descriptive.R")
    source("run_models.R")
    scripts_have_run <- TRUE
}
```

# Overview of the problem

Patients on dual antiplatelet therapy to reduce their ischaemic risk are at increased risk of bleeding. Risk factors for both bleeding and ischaemia have been previously investigated in several studies, and several qualitative risk scores exist. These are often based on a mixture of patient characteristics at the time of the intervention (such as current comorbidities), and patient history of related diagnoses and procedures. The purpose of this report is to try to extract this information, or proxies for this information, from hospital episodes statistics (HES) data and mortality data from the V.

More detailed relevant information is available from other data sources -- for example, the record of blood test results stored in hospital systems. However, a trade-off exists between finding data sources that are generic enough that they are likely available everywhere, vs. data sources that may not be easily generalized. HES data is the simplest data sources that is guaranteed to be present for all hospitals in the UK. HES data is not a real-time data source, but can be used to initially develop and validate different approaches to ischaemia/bleeding risk modelling.

In this report, several classification models are used to predict bleeding/ischaemia. A summary of the modelling results is shown in the table below. For more information, see [Classification models].

```{r echo=FALSE, message=FALSE, warning=FALSE, results="asis"}
all_model_auc_summary %>%
    kable(caption = "Summary of model performances. The mean area under the ROC curve was obtained by averaging bootstrapped resamples. The 95% error on this estimate is also shown.")
```

## Hospital episode statistics

Hospital episodes statistics (HES) contain diagnosis and procedure information from consultant episodes in secondary care. Each episode contains one or multiple diagnoses or procedures, which may be used to identify patients of interest, and track subsequent diagnoses and procedures in a follow-up period.

Hospital episodes are grouped into spells. A spell defines one in-patient hospital visit for a patient. A spell may contain multiple episodes because a patient may be attended by multiple consultants over the course of their hospital stay.

# Dataset definition and characteristics

Each row of the dataset corresponds to an episode with either an ACS or PCI code in any of the primary or secondary columns in the HES data. At most one index event is selected from each spell -- this is intended to avoid double counting the same underlying event (if, for example, two episodes are marked ACS in a single spell corresponding to one emergency admission due to a heart attack). The graph below shows the volume of index events (any ACS or PCI) as a function of time, broken down by STEMI (ST-elevation myocardial infarction) vs. NSTEMI (not STEMI) presentation.

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=6}
plot_index_with_time(raw_dataset)
```

The start date of the first episode of the index spell is used as the index date. A flag records whether the triggering event was a diagnosis (ACS) or a procedure (PCI). The patient age at that episode is recorded. There are `r num_index_events` index events in the dataset, from `r num_patients` patients, between the dates `r first_index_date` and `r last_index_date`. 

For each patient, all other diagnoses and procedures in all primary and secondary fields of all other episodes are retrieved. The number of occurrences of diagnosis and procedure code groups (as defined in the codes definition file; see the appendix) are counted up in a defined period before and after the index event. The results of this tally form the majority of the columns of the dataset. 

Mortality information, obtained from the Civil Registration of Deaths, is included in the dataset. Where a patient has died, the primary cause of death is recorded (an ICD 10 code), along with the date of death. This information is used to establish the patient survival time after index (only present for patients who have died), and categorize the cause of death as cardiovascular death (due to ACS, other ischaemic heart diseases and ischaemic stroke), or all-cause (any other cause of death).

The table below shows the proportion of different types of events occurring after the index event, broken down by STEMI vs. NSTEMI presentation.

```{r echo=FALSE, message=FALSE, warning=FALSE, results="asis"}
percentage_events_after_index %>%
    kable(caption = "Summary of proportion of different events occuring within 12 months of the index event, broken down by STEMI vs. NSTEMI presentation (NOTE: any-cause death figures might be low).")
```

Distribution of non-zero bleeding/ischaemia counts (uses a cutoff of 20 events to remove the long tail).

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=6}
plot_non_zero_count_distributions(raw_dataset)
```

The plot below shows the distribution of survival times, broken down by STEMI/NSTEMI presentation and cause of death.

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=6}
plot_survival(raw_dataset)
```

\newpage
## Distribution of predictors by outcome

The four quadrants show the four possible bleeding/ischaemia outcomes, along with the mean number of occurrences of the event on the x-axis before the ACS event. 

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=11}
plot_predictors_distributions(raw_dataset)
```

\newpage
## Other subsequent events

This is a plot of the distribution of counts of other subsequent events (not just bleeding and ischaemia), broken down by the bleeding and ischaemia endpoints.

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=11}
plot_outcome_distributions(raw_dataset)
```

\newpage
## Age distributions by outcome

The plots show the distribution of age in each of the outcome groups.

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=11}
plot_age_distributions(raw_dataset)
```

\newpage
# Classification models

Four classification models were fitted to the data: logistic regression; linear discriminant analysis; a basic decision tree; and naive Bayes.

## Finding the optimal model

Optimal models of each type were obtained by average model performance (over a set of cross-validation folds) for a grid of model hyper-parameters, and selecting the model with the highest mean ROC AUC value. For models with no hyper-parameters (e.g. logistic regression), a single model was obtained by fitting to the whole training set. 

## Identifying variability in the optimal model

In order to obtain a measure of variability of output risk predictions, the optimal model (i.e. with a fixed set of tuning parameters) was fitted to a set of bootstrapped resamples of the training data. The resulting set of models have slightly different ROC AUCs, and generate slightly different estimates for the bleeding and ischaemia risk for a given patient. This variability shows how randomness in the fitting process (due to variations in the training set used for fitting) translates to variations in the output probabilities.


Before fitting the models, near-zero variance predictors were removed as described in the section below.

## Variables selected in preprocessing

The full set of predictors input into the modelling process were:

```{r echo=FALSE}
bleeding_recipe %>%
    summary() %>%
    filter(role == "predictor") %>%
    pull(variable)
```

The preprocessing steps filter out variables that do not have enough variability to contribute to model performance. The remaining predictors after the preprocessing steps are listed below.

```{r echo=FALSE, message=FALSE, warning=FALSE}
##for_correlations <- raw_dataset %>%
##    dplyr::select(bleeding_after, ischaemia_after, all_of(remaining_predictors))
##correlations = cor(for_correlations)
##corrplot(correlations)
##remaining_predictors

bleeding_recipe %>%
    retained_predictors()    
```

## Logistic Regression

The ROC curves for the bleeding and ischaemia models are shown below:

```{r echo=FALSE, message=FALSE, warning=FALSE}
logistic_regression_results$roc_curves %>%
    plot_resample_roc_curves()
```

The lift curves for the bleeding and ischaemia models are shown below:

```{r echo=FALSE, message=FALSE, warning=FALSE}
logistic_regression_results$lift_curves %>%
    plot_resample_lift_curves()
```

The gain curves for the bleeding and ischaemia models are shown below:

```{r echo=FALSE, message=FALSE, warning=FALSE}
logistic_regression_results %>%
    plot_resample_gain_curves()
```


```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=11}
## Plot the ROC curves
## roc_curves %>%
##     filter(outcome_name == "ischaemia") %>%
##     left_join(roc_summary, by = join_by(model_name, outcome_name))%>%
##     mutate(model_name = str_to_title(str_replace(model_name, "_", " "))) %>%
##     ggplot(aes(x = 1 - specificity, y = sensitivity,
##                color = primary,
##                group = interaction(model_name, outcome_name, model_id))) +
##     geom_line(data = . %>% filter(primary == "bootstrap"),aes(col = "Bootstrap"), alpha = 0.5, size =1.05) +
##     geom_line(data = . %>% filter(primary == "primary"),aes(col = "Primary"),size = 1.05) +
##     geom_abline(slope = 1, intercept = 0, size = 0.4) +
##     geom_text(aes(x = 0.75, y = 0.25, label = glue::glue("AUC = {round(`Mean AUC`[.data$primary == primary], digits = 2)}")),
##               col = "black",  hjust =0, vjust = 0) +
##     coord_fixed() +
##     theme_minimal(base_size = 16) +
##     labs(title = "ROC curves for the ischaemia risk models") +
##     facet_wrap( ~ model_name, ncol=2)
```

\newpage
## ROC curves for the ischaemia risk models

The ROC curves for the ischaemia prediction models are shown below.

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=11}
## Plot the ROC curves
## roc_curves %>%
##     filter(outcome_name == "ischaemia") %>%
##     left_join(roc_summary, by = join_by(model_name, outcome_name))%>%
##     mutate(model_name = str_to_title(str_replace(model_name, "_", " "))) %>%
##     ggplot(aes(x = 1 - specificity, y = sensitivity,
##                color = primary,
##                group = interaction(model_name, outcome_name, model_id))) +
##     geom_line(data = . %>% filter(primary == "bootstrap"),aes(col = "Bootstrap"), alpha = 0.5, size =1.05) +
##     geom_line(data = . %>% filter(primary == "primary"),aes(col = "Primary"),size = 1.05) +
##     geom_abline(slope = 1, intercept = 0, size = 0.4) +
##     geom_text(aes(x = 0.75, y = 0.25, label = glue::glue("AUC = {round(`Mean AUC`[primary == 'primary'], digits = 2)}")),
##               col = "black",  hjust =0, vjust = 0) +
##     coord_fixed() +
##     theme_minimal(base_size = 16) +
##     labs(title = "ROC curves for the ischaemia risk models") +
##    facet_wrap( ~ model_name, ncol=2)
```

\newpage
## Variability in risk predictions by model

The purpose of this plot is to assess the variability inherent in fitting each model, and the variability between models. Each model has a small cluster (from bootstrap resampling), and the proximity of the clusters shows how well the models agree.

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=10}
## For one patient, plot all the model predictions. This graph is supposed
## to test how well the models agree with one another. The bootstrap models
## and the primary model are all plotted as dots (not distinguished).
## grouped_pred %>%
##     ungroup() %>%
##     dplyr::select(index_id, model_name, outcome_name,
##                   primary, model_id, .pred_occurred) %>%
##     pivot_wider(names_from = "outcome_name",
##                 values_from = ".pred_occurred") %>%
##     ## Pick only one patient. The idea is to plot all the predictions for just
##     ## that one patient
##     filter(index_id %in% sample(index_id, size = 4)) %>%
##     ## Uncomment to view all models for some patients
##     ##filter(id %in% c(1,20,23,43, 100, 101, 102)) %>%
##     ggplot(aes(x = bleed, y = ischaemia, color=model_name, shape = primary)) +
##     geom_point() +
##     ## scale_y_log10() +
##     ## scale_x_log10() +
##     labs(title = "Plot of risk predictions from all models for some patients") +
##     facet_wrap( ~ index_id, ncol=2) +
##    theme_minimal(base_size = 16)
```

\newpage
## Risk trade-off plots for each model

Plots of risk trade-off for each model. The plot includes the model predictions corresponding to STEMI presentations explicitly.

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=10}
## Plot of the risk trade-off graph for each model (using the primary model)
## grouped_pred %>%
##     ungroup() %>%
##     filter(primary == "primary") %>%
##     dplyr::select(stemi_presentation, index_id, outcome_name, model_name, .pred_occurred) %>%
##     pivot_wider(names_from = outcome_name, values_from = .pred_occurred) %>%
##     ggplot(aes(x = bleed, y = ischaemia, color = stemi_presentation)) +
##     geom_point() +
##     facet_wrap( ~ model_name, ncol=2) +
##    theme_minimal(base_size = 16)
```

\newpage
# Appendix

A bespoke program reads the ICD and OPCS codes in the HES database and parses them into code groups, shown in the sections below.

## ICD 10 codes in the dataset

The groups of ICD 10 diagnosis codes used in the analysis are shown below:

```{r echo=FALSE, message=FALSE, warning=FALSE, results="asis"}
groups <- code_groups("../../icd10.yaml")
for (n in seq_along(groups)) {
    print(kable(groups[[n]], caption = paste("Diagnosis group", names(groups)[[n]])))
}
```

## OPCS 4 codes in the dataset

The groups of OPCS 4 procedure codes used in the analysis are shown below:

```{r echo=FALSE, message=FALSE, warning=FALSE, results="asis"}
groups <- code_groups("../../opcs4.yaml")
for (n in seq_along(groups)) {
    print(kable(groups[[n]], caption = paste("Procedure group", names(groups)[[n]])))
}
```



<!--  LocalWords:  acs
 -->
